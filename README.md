# End-to-End Social Media Sentiment Scraper with DB, API & Visualizer  
### Reddit-Only MVP Roadmap

**Author:** Sumayer Khan Sajid (ID 2221818642)  
**Course:** CSE299 â€“ Junior Development Project, North South University  
**Status:** ğŸŸ¢ Environment & Repo Readyâ€ƒğŸŸ  Building Reddit Collector

---

## ğŸ¯ Goal
Build a minimal, end-to-end pipeline that:
1. Fetches Reddit posts for a given keyword via the official API  
2. Cleans and normalizes text  
3. Applies VADER sentiment analysis  
4. Stores results in a structured database  
5. Serves sentiment summaries through an API and a simple dashboard  

This MVP focuses only on **Reddit**.  
Future versions will add X/Twitter and more platforms.

---

## ğŸ§© Project Structure
\`\`\`
collector/        â†’ Reddit API fetchers
preprocessing/    â†’ Text cleaning functions
analysis/         â†’ VADER sentiment scripts
database/         â†’ DB schema & connectors
api/              â†’ REST API (Flask/FastAPI)
dashboard/        â†’ Streamlit UI for visualization
utils/            â†’ Config, logger, helpers
data/             â†’ Temporary raw & processed files (ignored by Git)
\`\`\`

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Clone & Environment
\`\`\`bash
git clone https://github.com/SumayerKhan/End-to-End_Social_Media_Sentiment_Scraper_DB_API_Visualizer.git
cd End-to-End_Social_Media_Sentiment_Scraper_DB_API_Visualizer
python -m venv venv
source venv/bin/activate     # on Windows: venv\Scripts\activate
pip install -r requirements.txt
\`\`\`

### 2ï¸âƒ£ Environment Variables (\`.env\`)
Copy \`.env.example\` â†’ \`.env\` and fill in your secrets:

\`\`\`
REDDIT_CLIENT_ID=xxxx
REDDIT_CLIENT_SECRET=xxxx
REDDIT_USER_AGENT=sentiment_scraper:v1.0 (by u/YourUsername)
DB_HOST=localhost
DB_USER=root
DB_PASSWORD=yourpassword
DB_NAME=sentiment_db
\`\`\`

---

## ğŸ§  MVP Workflow
\`\`\`
Keyword â†’ Reddit API â†’ Preprocessing â†’ VADER â†’ Database â†’ API â†’ Dashboard
\`\`\`

| Phase | Goal | Status |
|-------|------|--------|
| Phase 0 | Repo & venv setup | âœ… Done |
| Phase 1 | Reddit collector (fetch + save) | ğŸ”„ In progress |
| Phase 2 | Preprocessing (clean text) | â³ Pending |
| Phase 3 | Sentiment (VADER) | â³ Pending |
| Phase 4 | Database integration | â³ Pending |
| Phase 5 | API + dashboard slice | â³ Pending |
| Phase 6 | MVP stabilization & docs | â³ Pending |

---

## ğŸ§¾ Key Decisions
- **Ethical API access:** Use official Reddit API (PRAW) for data collection.  
- **Model:** VADER (lexicon + rule-based, social-media optimized).  
- **Database:** MySQL or PostgreSQL with three tables â€“ \`raw_posts\`, \`processed_posts\`, \`sentiment_posts\`.  
- **Visualization:** Streamlit dashboard showing daily positive/neutral/negative trends.  

---

## ğŸ§° Development Notes
- Work on feature branches (\`feature/reddit-collector\`, \`feature/vader-analysis\`, etc.)  
- Merge into \`dev\` after each tested module, then to \`main\` when stable.  
- Keep \`data/\` and \`.env\` out of Git (\`.gitignore\` handles this).  

---

## ğŸš€ Running the Pipeline (MVP)
1. Activate venv  
2. Run \`collector/reddit_collector.py\` for a keyword  
3. Inspect \`data/raw/reddit_sample.json\` to verify API output  
4. Proceed with preprocessing â†’ VADER â†’ DB insertion  
5. Launch dashboard to view sentiment trend  

---

## ğŸ§­ Next Steps
- âœ… Finish Reddit collector  
- ğŸ§¹ Implement text cleaning pipeline  
- ğŸ’¬ Integrate VADER sentiment scores  
- ğŸ—ƒï¸ Design and connect database schema  
- ğŸ“ˆ Build minimal API and dashboard for visual output  

---

## ğŸ“„ License & Acknowledgement
For academic use (CSE299 â€“ North South University).  
Uses Reddit API data under their public usage policy.  
VADER sentiment model by Hutto & Gilbert (2014).

---